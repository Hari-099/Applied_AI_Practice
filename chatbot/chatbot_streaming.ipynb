{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4c9dbf-b78f-445d-a3d9-9c6b36240034",
   "metadata": {},
   "source": [
    "# ChatBot System Design (Streaming Similar to ChatGPT)\n",
    "\n",
    "## Technologies Used\n",
    "- **Frontend:** ReactJS\n",
    "- **Backend:** Python (FastAPI)\n",
    "- **Streaming/Reactive Programming:** React Programming\n",
    "- **Message Broker:** Kafka\n",
    "\n",
    "## High-Level Design Steps\n",
    "\n",
    "### 1. User Query Input\n",
    "- Users can ask queries to the ChatBot through a user-friendly interface built with ReactJS.\n",
    "\n",
    "### 2. Request Handling\n",
    "- The userâ€™s query will be sent to the backend where Python's FastAPI will handle the request.\n",
    "- Implement streaming or reactive programming concepts to process the incoming messages.\n",
    "- The message should then be published to a Kafka topic.\n",
    "\n",
    "### 3. Kafka High-Level Design\n",
    "\n",
    "#### Data Storage and Retrieval\n",
    "- Use Kafka topics to store incoming queries and system-generated responses.\n",
    "- Consider using separate topics for different stages of the message lifecycle:\n",
    "  - `user_queries`\n",
    "  - `system_responses`\n",
    "\n",
    "### 4. Generate System Response\n",
    "- Once a query is received in the Kafka topic, a consumer service will read the message and generate an appropriate response.\n",
    "- This response will then be stored in another Kafka topic (`system_responses`).\n",
    "\n",
    "### 5. Response Delivery\n",
    "- A Kafka producer will read the system-generated response from the `system_responses` topic.\n",
    "- The producer will use Python's FastAPI to push the response back to the ReactJS front-end to be displayed to the user in real-time.\n",
    "\n",
    "## High-Level Flow Diagram\n",
    "\n",
    "```plaintext\n",
    "+---------------+        +----------------+      +------------------+      +-------------------+\n",
    "|               |        |                |      |                  |      |                   |\n",
    "|  User Query   +------->+  FastAPI        +----->+  Kafka Topic      +----->+  Consumer Service  |\n",
    "|   (ReactJS)   |        |   (Backend)     |      |  (user_queries)  |      |  (Generate Response)|\n",
    "|               |        |                |      |                  |      |                   |\n",
    "+---------------+        +----------------+      +------------------+      +-------------------+\n",
    "                                                                            |\n",
    "                                                                            v\n",
    "+---------------+        +----------------+      +------------------+      +-------------------+\n",
    "|               |        |                |      |                  |      |                   |\n",
    "| System Response+<-------+  FastAPI        +<-----+  Kafka Topic      +<-----+  Producer Service |\n",
    "|   (ReactJS)   |        |   (Backend)     |      |  (system_responses)|      |   (Push Response) |\n",
    "|               |        |                |      |                  |      |                   |\n",
    "+---------------+        +----------------+      +------------------+      +-------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c954ff5-3f13-48c4-a85e-13b5bef6ff88",
   "metadata": {},
   "source": [
    "# ReactJS - User Input and Display\n",
    "\n",
    "## src/App.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604da71-e7ac-4571-a0e3-f0c8ecd8aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import React, { useState } from 'react';\n",
    "import './App.css';\n",
    "\n",
    "function App() {\n",
    "  const [query, setQuery] = useState('');\n",
    "  const [response, setResponse] = useState('');\n",
    "\n",
    "  const handleQueryChange = (e) => {\n",
    "    setQuery(e.target.value);\n",
    "  };\n",
    "\n",
    "  const handleQuerySubmit = async () => {\n",
    "    const res = await fetch('http://localhost:8000/query', {\n",
    "      method: 'POST',\n",
    "      headers: { 'Content-Type': 'application/json' },\n",
    "      body: JSON.stringify({ query })\n",
    "    });\n",
    "    const data = await res.json();\n",
    "    setResponse(data.response);\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"App\">\n",
    "      <header className=\"App-header\">\n",
    "        <h1>ChatBot</h1>\n",
    "        <input \n",
    "          type=\"text\" \n",
    "          value={query} \n",
    "          onChange={handleQueryChange} \n",
    "          placeholder=\"Ask your question...\" \n",
    "        />\n",
    "        <button onClick={handleQuerySubmit}>Submit</button>\n",
    "        <p>Response: {response}</p>\n",
    "      </header>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ffb50-1e6f-449b-bcb8-81149975a470",
   "metadata": {},
   "source": [
    "### `src/index.css`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4c65f-a664-47fd-987e-907dde096f02",
   "metadata": {},
   "outputs": [],
   "source": [
    ".App {\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    ".App-logo {\n",
    "  height: 40vmin;\n",
    "  pointer-events: none;\n",
    "}\n",
    "\n",
    ".App-header {\n",
    "  background-color: #282c34;\n",
    "  min-height: 100vh;\n",
    "  display: flex;\n",
    "  flex-direction: column;\n",
    "  align-items: center;\n",
    "  justify-content: center;\n",
    "  font-size: calc(10px + 2vmin);\n",
    "  color: white;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71b8a0-a94f-4249-b96b-ec76e0d3ca6d",
   "metadata": {},
   "source": [
    "<h1>Python FastAPI - Backend to Handle Query and Kafka Integration</h1>\n",
    "\n",
    "<h2>app/main.py</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46106379-2075-440e-95d4-698ffb7b5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "class Query(BaseModel):\n",
    "    query: str\n",
    "\n",
    "@app.post(\"/query\")\n",
    "async def create_query(query: Query):\n",
    "    producer.send('user_queries', {'query': query.query})\n",
    "    producer.flush()\n",
    "    \n",
    "    consumer = KafkaConsumer(\n",
    "        'system_responses',\n",
    "        bootstrap_servers='localhost:9092',\n",
    "        auto_offset_reset='earliest',\n",
    "        enable_auto_commit=True,\n",
    "        group_id='consumer-group-a'\n",
    "    )\n",
    "    \n",
    "    for message in consumer:\n",
    "        response = json.loads(message.value.decode('utf-8'))\n",
    "        if response['query'] == query.query:\n",
    "            return {\"response\": response['response']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b80a21-5c3f-4586-8d38-9d9a3757ca1f",
   "metadata": {},
   "source": [
    "<h1>Kafka Consumer - System Response Generator</h1>\n",
    "\n",
    "<h2>consumer.py</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6579ebf-85f3-4d85-b46b-99c5ebeb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'user_queries',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='consumer-group-b'\n",
    ")\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "for message in consumer:\n",
    "    query = json.loads(message.value.decode('utf-8'))['query']\n",
    "    response = f\"Generated response for '{query}'\"\n",
    "    producer.send('system_responses', {'query': query, 'response': response})\n",
    "    producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab42ce-54cb-4cac-b477-fd225fc6f6ad",
   "metadata": {},
   "source": [
    "# Create the Producer Service\n",
    "<b>`main.py`</b> - FastAPI Application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa51afb-06af-4c9d-be0a-c349f90e861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from confluent_kafka import Producer, KafkaError\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Kafka configuration\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'linger.ms': 10\n",
    "}\n",
    "kafka_topic = 'system_responses'\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = Producer(kafka_config)\n",
    "\n",
    "class ResponseMessage(BaseModel):\n",
    "    user_id: int\n",
    "    message: str\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\" Called once for each message produced to indicate delivery result.\n",
    "        Triggered by poll() or flush(). \"\"\"\n",
    "    if err is not None:\n",
    "        print('Message delivery failed: {}'.format(err))\n",
    "    else:\n",
    "        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "@app.post(\"/produce/\")\n",
    "async def produce_message(response_message: ResponseMessage):\n",
    "    try:\n",
    "        # Produce message to Kafka\n",
    "        producer.produce(\n",
    "            kafka_topic,\n",
    "            key=str(response_message.user_id),\n",
    "            value=response_message.message,\n",
    "            callback=delivery_report\n",
    "        )\n",
    "        producer.poll(0)\n",
    "        producer.flush()\n",
    "        return {\"status\": \"message sent\"}\n",
    "    except KafkaError as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Kafka error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8db681-9410-4493-b6c2-11a38466930d",
   "metadata": {},
   "source": [
    "## Modularize Kafka implementation\n",
    "\n",
    "<b>Project Structure</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0841476-1d6f-4a99-bc62-1e6a4d2c156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_producer_service/\n",
    "â”œâ”€â”€ main.py\n",
    "â”œâ”€â”€ api/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â””â”€â”€ producer.py\n",
    "â””â”€â”€ kafka/\n",
    "    â”œâ”€â”€ __init__.py\n",
    "    â””â”€â”€ config.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be5a63-8cc2-4dc5-a229-be462e1224ea",
   "metadata": {},
   "source": [
    "1. <b>`kafka/config.py`</b> -<h3> Kafka Configuration</h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393baf1-73c2-4292-8430-9d3f1b0477b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "def get_kafka_producer():\n",
    "    kafka_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',\n",
    "        'linger.ms': 10\n",
    "    }\n",
    "    return Producer(kafka_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff2fbb-d237-4c32-b344-692d71c6dbac",
   "metadata": {},
   "source": [
    "2. <b>`api/producer.py`<b> - <h3>Producer API</h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a9aed-4554-4650-938b-ed9c8a573fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import APIRouter, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from confluent_kafka import KafkaError\n",
    "from kafka.config import get_kafka_producer\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = get_kafka_producer()\n",
    "kafka_topic = 'system_responses'\n",
    "\n",
    "class ResponseMessage(BaseModel):\n",
    "    user_id: int\n",
    "    message: str\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\" Called once for each message produced to indicate delivery result.\n",
    "        Triggered by poll() or flush(). \"\"\"\n",
    "    if err is not None:\n",
    "        print('Message delivery failed: {}'.format(err))\n",
    "    else:\n",
    "        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "@router.post(\"/produce/\")\n",
    "async def produce_message(response_message: ResponseMessage):\n",
    "    try:\n",
    "        # Produce message to Kafka\n",
    "        producer.produce(\n",
    "            kafka_topic,\n",
    "            key=str(response_message.user_id),\n",
    "            value=response_message.message,\n",
    "            callback=delivery_report\n",
    "        )\n",
    "        producer.poll(0)\n",
    "        producer.flush()\n",
    "        return {\"status\": \"message sent\"}\n",
    "    except KafkaError as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Kafka error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09d89d-5dea-424c-b495-6e3cf8c94e68",
   "metadata": {},
   "source": [
    "3. <b>`main.py`</b> - <h3>FastAPI Application Entry Point</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4ca5f-1c44-4c80-98a0-20e994945187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from api.producer import router as producer_router\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Include the producer router\n",
    "app.include_router(producer_router, prefix=\"/api\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b21158-41d4-4701-b8ae-a154f1ecc941",
   "metadata": {},
   "source": [
    "<h1>Setup Kafka Topics</h1>\n",
    "\n",
    "<p>Make sure to create the necessary Kafka topics (<code>user_queries</code> and <code>system_responses</code>) in your Kafka instance.</p>\n",
    "\n",
    "<p>This is a skeletal structure to get you started. You can extend it by adding more robust error handling, optimizations, and additional features as per your requirements.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e89f4-b20d-4381-bc9e-21a71148aaa1",
   "metadata": {},
   "source": [
    "# WebSocketss D generator;\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05463637-8155-4332-81f2-49b041f57ca2",
   "metadata": {},
   "source": [
    "graph TD;\n",
    "    A[ReactJS (Frontend)] -->|WebSocket Connection| B[WebSocket Server];\n",
    "    B -->|Produce Message| C[(Kafka)];\n",
    "    C -->|Consume Message| D[System Response Generator];\n",
    "    D -->|Produce Response| C;\n",
    "    C -->|Consume Response| B;\n",
    "    B -->|Send Response| A;\n",
    "\n",
    "    classDef react fill:#f9f,stroke:#333,stroke-width:2px;\n",
    "    classDef ws fill:#6f9,stroke:#333,stroke-width:2px;\n",
    "    classDef kafka fill:#9cf,stroke:#333,stroke-width:2px;\n",
    "    classDef generator fill:#fc9,stroke:#333,stroke-width:2px;\n",
    "\n",
    "    class A react;\n",
    "    class B ws;\n",
    "    class C kafka;\n",
    "    class D generator;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281d955-a72c-47b2-b5e5-35789b848087",
   "metadata": {},
   "source": [
    "<h1>Design Overview</h1>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>ReactJS (Frontend):</strong>\n",
    "    <ul>\n",
    "      <li>User inputs and displays the response.</li>\n",
    "      <li>Communicates with the backend via WebSocket.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><strong>WebSocket Server (Backend):</strong>\n",
    "    <ul>\n",
    "      <li>Handles incoming queries from the frontend.</li>\n",
    "      <li>Produces messages to Kafka.</li>\n",
    "      <li>Consumes messages from Kafka and sends responses back to the frontend.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><strong>Kafka:</strong>\n",
    "    <ul>\n",
    "      <li>Acts as a message broker between the WebSocket server and the system response generator.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><strong>Consumer for System Response Generator:</strong>\n",
    "    <ul>\n",
    "      <li>Consumes user queries from Kafka.</li>\n",
    "      <li>Generates responses and produces them back to Kafka.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<h1>Implementation</h1>\n",
    "\n",
    "<h2>1. ReactJS</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfa4c5-5abd-4322-90ea-9dc7e0f6d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import React, { useState, useEffect } from 'react';\n",
    "import './App.css';\n",
    "\n",
    "function App() {\n",
    "  const [query, setQuery] = useState('');\n",
    "  const [response, setResponse] = useState('');\n",
    "  const [socket, setSocket] = useState(null);\n",
    "\n",
    "  useEffect(() => {\n",
    "    const ws = new WebSocket('ws://localhost:8000');\n",
    "    ws.onmessage = (event) => {\n",
    "      const data = JSON.parse(event.data);\n",
    "      setResponse(data.response);\n",
    "    };\n",
    "    setSocket(ws);\n",
    "\n",
    "    return () => {\n",
    "      ws.close();\n",
    "    };\n",
    "  }, []);\n",
    "\n",
    "  const handleQueryChange = (e) => {\n",
    "    setQuery(e.target.value);\n",
    "  };\n",
    "\n",
    "  const handleQuerySubmit = () => {\n",
    "    socket.send(JSON.stringify({ query }));\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"App\">\n",
    "      <header className=\"App-header\">\n",
    "        <h1>ChatBot</h1>\n",
    "        <input \n",
    "          type=\"text\" \n",
    "          value={query} \n",
    "          onChange={handleQueryChange} \n",
    "          placeholder=\"Ask your question...\" \n",
    "        />\n",
    "        <button onClick={handleQuerySubmit}>Submit</button>\n",
    "        <p>Response: {response}</p>\n",
    "      </header>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2ead7-a115-4fb2-8296-030981aeef2f",
   "metadata": {},
   "source": [
    "<h2>2. WebSocket Server</h2>\n",
    "\n",
    "<p>First, install the necessary libraries:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a497713-29b1-48d6-813d-1a466b4bb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install websockets kafka-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe007a-fac5-4335-81c1-864eec2ebfca",
   "metadata": {},
   "source": [
    "<h2>app/server.py</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1212e91-2ccc-484a-95bb-a012e7b336e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "async def handle_client(websocket, path):\n",
    "    consumer = KafkaConsumer(\n",
    "        'system_responses',\n",
    "        bootstrap_servers='localhost:9092',\n",
    "        auto_offset_reset='earliest',\n",
    "        enable_auto_commit=True,\n",
    "        group_id=str(uuid.uuid4())  # Unique group_id for each connection\n",
    "    )\n",
    "\n",
    "    async for message in websocket:\n",
    "        query_data = json.loads(message)\n",
    "        producer.send('user_queries', query_data)\n",
    "        producer.flush()\n",
    "        \n",
    "        for msg in consumer:\n",
    "            response_data = json.loads(msg.value.decode('utf-8'))\n",
    "            if response_data['query'] == query_data['query']:\n",
    "                await websocket.send(json.dumps({'response': response_data['response']}))\n",
    "                break\n",
    "\n",
    "start_server = websockets.serve(handle_client, \"localhost\", 8000)\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(start_server)\n",
    "asyncio.get_event_loop().run_forever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c566662-6a93-421d-9fef-8a3d1f59305d",
   "metadata": {},
   "source": [
    "<h2>3. Kafka Consumer for System Response Generator</h2>\n",
    "\n",
    "<h3>consumer.py</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cfbc0-5272-406a-a1d8-a1283bfb998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'user_queries',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='consumer-group-b'\n",
    ")\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "for message in consumer:\n",
    "    query = json.loads(message.value.decode('utf-8'))['query']\n",
    "    response = f\"Generated response for '{query}'\"\n",
    "    producer.send('system_responses', {'query': query, 'response': response})\n",
    "    producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44022c4-527a-4276-a4cf-fee969427cef",
   "metadata": {},
   "source": [
    "<h2>Setup Kafka Topics</h2>\n",
    "\n",
    "<p>Make sure to create the necessary Kafka topics (<code>user_queries</code> and <code>system_responses</code>) in your Kafka instance.</p>\n",
    "\n",
    "<p>This setup allows you to communicate from the React app to the WebSocket server, which interacts with Kafka and retrieves/generates responses dynamically. The components are decoupled and can scale independently.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f027f4-25c7-4b58-b8cf-c377f9ba7bc4",
   "metadata": {},
   "source": [
    "# Code Coverage or Test Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a3baa-97fa-422d-9f5e-1dcf51500d3f",
   "metadata": {},
   "source": [
    "1. <b>`tests/test_messages.py`</b>\n",
    "This file will contain all of our test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42aa45b-dfed-4605-8120-40e3e37a8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from fastapi.testclient import TestClient\n",
    "from main import app\n",
    "from unittest.mock import patch, MagicMock\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "import pytz\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_get_user():\n",
    "    return {\"id\": 1, \"name\": \"Test User\"}\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_session():\n",
    "    session = MagicMock()\n",
    "    yield session\n",
    "    session.close()\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_audio_file():\n",
    "    return UploadFile(\n",
    "        filename=\"test_audio.mp3\",\n",
    "        content_type=\"audio/mpeg\",\n",
    "        file=BytesIO(b\"dummy audio contents\")\n",
    "    )\n",
    "\n",
    "@patch(\"main.get_user\", side_effect=mock_get_user)\n",
    "@patch(\"main.get_session\", side_effect=mock_session)\n",
    "def test_send_message_without_audio(mock_get_user, mock_get_session):\n",
    "    response = client.post(\"/messages\", json={\"question\": \"What is the weather today?\"})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "@patch(\"main.get_user\", side_effect=mock_get_user)\n",
    "@patch(\"main.get_session\", side_effect=mock_session)\n",
    "def test_send_message_with_empty_audio(mock_get_user, mock_get_session):\n",
    "    empty_audio = UploadFile(\n",
    "        filename=\"test_audio.mp3\",\n",
    "        content_type=\"audio/mpeg\",\n",
    "        file=BytesIO(b\"\")\n",
    "    )\n",
    "    response = client.post(\"/messages\", files={\"audio\": empty_audio.file})\n",
    "    assert response.status_code == 400\n",
    "    assert response.json() == {\"detail\": \"Uploaded audio file is empty\"}\n",
    "\n",
    "@patch(\"main.get_user\", side_effect=mock_get_user)\n",
    "@patch(\"main.get_session\", side_effect=mock_session)\n",
    "def test_send_message_with_audio(mock_get_user, mock_get_session, mock_audio_file):\n",
    "    response = client.post(\"/messages\", files={\"audio\": mock_audio_file.file})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "@patch(\"main.get_user\", side_effect=mock_get_user)\n",
    "@patch(\"main.get_session\", side_effect=mock_session)\n",
    "def test_send_message_with_conversation_id(mock_get_user, mock_get_session):\n",
    "    conversation_id = 1234\n",
    "    response = client.post(\"/messages\", json={\"conversation_id\": conversation_id, \"question\": \"Tell me a joke.\"})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "@patch(\"main.get_user\", side_effect=mock_get_user)\n",
    "@patch(\"main.get_session\", side_effect=mock_session)\n",
    "def test_send_message_without_question_and_audio(mock_get_user, mock_get_session):\n",
    "    response = client.post(\"/messages\")\n",
    "    assert response.status_code == 400\n",
    "    assert response.json() == {\"detail\": \"Text or audio file is required\"}\n",
    "\n",
    "# Add more tests as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777bd1f-900a-4d61-9132-b458fb9b5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from fastapi.testclient import TestClient\n",
    "from main import app\n",
    "from unittest.mock import patch, MagicMock\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "import pytz\n",
    "from fastapi import UploadFile  # Fix: Add this missing import\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_get_user():\n",
    "    return {\"id\": 1, \"name\": \"Test User\"}\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_session():\n",
    "    session = MagicMock()\n",
    "    yield session\n",
    "    session.close()\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_audio_file():\n",
    "    return UploadFile(\n",
    "        filename=\"test_audio.mp3\",\n",
    "        content_type=\"audio/mpeg\",\n",
    "        file=BytesIO(b\"dummy audio contents\")\n",
    "    )\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def override_dependencies(mock_get_user, mock_session):\n",
    "    with patch(\"main.get_user\", return_value=mock_get_user), \\\n",
    "         patch(\"main.get_session\", return_value=mock_session):\n",
    "        yield\n",
    "\n",
    "def test_send_message_without_audio():\n",
    "    response = client.post(\"/messages\", json={\"question\": \"What is the weather today?\"})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "def test_send_message_with_empty_audio():\n",
    "    empty_audio = UploadFile(\n",
    "        filename=\"test_audio.mp3\",\n",
    "        content_type=\"audio/mpeg\",\n",
    "        file=BytesIO(b\"\")\n",
    "    )\n",
    "    response = client.post(\"/messages\", files={\"audio\": (\"test_audio.mp3\", empty_audio.file, \"audio/mpeg\")})\n",
    "    assert response.status_code == 400\n",
    "    assert response.json() == {\"detail\": \"Uploaded audio file is empty\"}\n",
    "\n",
    "def test_send_message_with_audio(mock_audio_file):\n",
    "    response = client.post(\"/messages\", files={\"audio\": (mock_audio_file.filename, mock_audio_file.file, mock_audio_file.content_type)})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "def test_send_message_with_conversation_id():\n",
    "    conversation_id = 1234\n",
    "    response = client.post(\"/messages\", json={\"conversation_id\": conversation_id, \"question\": \"Tell me a joke.\"})\n",
    "    assert response.status_code == 200\n",
    "    assert \"messages\" in response.json()\n",
    "\n",
    "def test_send_message_without_question_and_audio():\n",
    "    response = client.post(\"/messages\")\n",
    "    assert response.status_code == 400\n",
    "    assert response.json() == {\"detail\": \"Text or audio file is required\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff000ecd-c446-47de-82fe-24f27ac209a4",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "**Fixtures:** Used to mock user data and session objects that will be passed to the endpoint.\n",
    "\n",
    "**Mocking Dependencies:** We patch the dependencies like `get_user` and `get_session` to return controlled data for our tests.\n",
    "\n",
    "### Test Cases\n",
    "\n",
    "- **test_send_message_without_audio:** Tests sending a message without an audio file.\n",
    "- **test_send_message_with_empty_audio:** Tests handling of an empty audio file.\n",
    "- **test_send_message_with_audio:** Tests sending a message with a valid audio file.\n",
    "- **test_send_message_with_conversation_id:** Tests sending a message with a specific conversation ID.\n",
    "- **test_send_message_without_question_and_audio:** Tests handling when both question and audio are missing.\n",
    "\n",
    "You can expand your tests by adding more scenarios and edge cases as needed.\n",
    "\n",
    "**Run the tests using:** \n",
    "```bash\n",
    "pytest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81f640-fae4-43e1-8fb5-b2e49b0e6837",
   "metadata": {},
   "source": [
    "******************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b4e82-667c-4751-bf98-0d9be4b42570",
   "metadata": {},
   "source": [
    "## consumer_service.py: Consuming and Producing with Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a64509-a205-44bc-b3fa-2d8261272660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from confluent_kafka import Consumer, KafkaException\n",
    "from producer_service import create_producer\n",
    "\n",
    "async def consume_and_produce(query_string):\n",
    "    consumer_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',\n",
    "        'group.id': 'my-consumer-group',\n",
    "        'enable.auto.commit': False,\n",
    "        'isolation.level': 'read_committed'\n",
    "    }\n",
    "\n",
    "    consumer = Consumer(consumer_config)\n",
    "    consumer.subscribe(['input_topic'])\n",
    "\n",
    "    # Producer configuration with transactions\n",
    "    producer = create_producer()\n",
    "    producer.init_transactions()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                continue\n",
    "            \n",
    "            if msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "\n",
    "            key = msg.key().decode('utf-8')\n",
    "            value = msg.value().decode('utf-8')\n",
    "\n",
    "            if query_string in value:\n",
    "                processed_value = value.upper()  # Example processing logic\n",
    "\n",
    "                try:\n",
    "                    producer.begin_transaction()\n",
    "                    producer.produce('output_topic', key=key.encode('utf-8'), value=processed_value.encode('utf-8'))\n",
    "                    producer.send_offsets_to_transaction(\n",
    "                        [msg],\n",
    "                        consumer_config['group.id']\n",
    "                    )\n",
    "                    producer.commit_transaction()\n",
    "\n",
    "                    consumer.commit(asynchronous=False)\n",
    "                    return {'key': key, 'value': processed_value}\n",
    "\n",
    "                except KafkaException as e:\n",
    "                    producer.abort_transaction()\n",
    "                    print(f\"Transaction aborted due to error: {e}\")\n",
    "                    raise\n",
    "    finally:\n",
    "        producer.flush()\n",
    "        consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e1e70-d776-466b-9b37-926ed876e8e7",
   "metadata": {},
   "source": [
    "## Create a new file named consumer.py and define your route there using FastAPI's APIRouter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f8274-f65d-4e60-9f8c-a8cb929fae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import APIRouter, HTTPException, Query\n",
    "from pydantic import BaseModel\n",
    "from consumer_service import consume_and_produce\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "class MessageResponse(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "@router.get('/consume', response_model=MessageResponse)\n",
    "async def consume(query_string: str = Query(..., min_length=1)):\n",
    "    try:\n",
    "        result = await consume_and_produce(query_string)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadfb5e-696f-438f-9242-35da98a019d7",
   "metadata": {},
   "source": [
    "<b>Now, import the router from consumer.py and include it in your FastAPI app in main.py.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761c464-d6b0-4912-9aaf-47eac1f8107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "from consumer import router as consumer_router\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Include the router\n",
    "app.include_router(consumer_router, prefix=\"/api\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app, host='0.0.0.0', port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a89bf1-6bcf-41ac-a5f4-baf7a19c7d3d",
   "metadata": {},
   "source": [
    "*******************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337e44d-6bf2-4986-ba00-b0fcfcd670e9",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Database Transaction Decorator</h2>\n",
    "<p>This decorator ensures that any function it wraps is executed within a database transaction. If the function raises an exception, the transaction is rolled back; otherwise, it is committed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672fe81-63f1-46c0-842b-61b0770d834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def transactional(session: Session):\n",
    "    try:\n",
    "        yield\n",
    "        session.commit()\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        raise e\n",
    "\n",
    "def transaction_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        session = kwargs.get('session')\n",
    "        if not session:\n",
    "            raise ValueError(\"Session is required\")\n",
    "        with transactional(session):\n",
    "            return func(*args, **kwargs)\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55be908-520d-4b66-948d-a9e311f902c2",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Kafka Consumer Decorator</h2>\n",
    "<p>This decorator consumes messages from a Kafka topic and passes them to the wrapped function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9864e-9809-4e62-a949-a7567a7724f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "\n",
    "def kafka_consumer_decorator(consumer_conf, topics):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            consumer = Consumer(consumer_conf)\n",
    "            consumer.subscribe(topics)\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    msg = consumer.poll(timeout=1.0)\n",
    "                    if msg is None:\n",
    "                        continue\n",
    "                    if msg.error():\n",
    "                        if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                            # End of partition event\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise KafkaException(msg.error())\n",
    "                    func(msg.value(), *args, **kwargs)\n",
    "            finally:\n",
    "                consumer.close()\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37650677-b7eb-4d1f-90d8-176b942cb01a",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Kafka Producer Decorator</h2>\n",
    "<p>This decorator sends messages to a Kafka topic after the wrapped function executes successfully.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96836071-3b3e-4b26-bfa8-e0166d583dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "producer_instance = None\n",
    "\n",
    "def get_producer(producer_conf):\n",
    "    global producer_instance\n",
    "    if not producer_instance:\n",
    "        producer_instance = Producer(producer_conf)\n",
    "    return producer_instance\n",
    "\n",
    "def kafka_producer_decorator(producer_conf, topic):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            producer = get_producer(producer_conf)\n",
    "            result = func(*args, **kwargs)\n",
    "            producer.produce(topic, key=None, value=result)\n",
    "            producer.flush()\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a68f2-9f71-431d-93f4-0b67fe0bcaba",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Example Usage</h2>\n",
    "<p>Hereâ€™s how you can use these decorators in your code:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a6701-5796-4795-8360-a8a71ae944c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Depends\n",
    "\n",
    "# Assume that get_db_session is a dependency that provides a database session\n",
    "from dependencies import get_db_session \n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Example of usage in a route with SQLAlchemy transactions\n",
    "@app.post('/transactional-endpoint')\n",
    "@transaction_decorator\n",
    "async def transactional_endpoint(data: dict, session: Session = Depends(get_db_session)):\n",
    "    # Your business logic here\n",
    "    ...\n",
    "\n",
    "# Example Kafka Consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "# Example Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "\n",
    "# Creating a function using Kafka consumer\n",
    "@kafka_consumer_decorator(consumer_config, ['my-topic'])\n",
    "def consume_kafka_message(message, *args, **kwargs):\n",
    "    print(f\"Consumed message: {message}\")\n",
    "\n",
    "# Using Kafka Producer in a function\n",
    "@kafka_producer_decorator(producer_config, 'output-topic')\n",
    "def process_data():\n",
    "    data = \"Processed Data\"\n",
    "    return data\n",
    "\n",
    "# Call the function to start consuming Kafka messages\n",
    "consume_kafka_message()\n",
    "\n",
    "# To produce a message\n",
    "process_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddf559-9e87-4526-9ec0-d4a7e5fb9c45",
   "metadata": {},
   "source": [
    "************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661caf5c-ce02-41a5-a4b5-73f2c2494dec",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Kafka Transaction Decorator</h2>\n",
    "<p>Creating a Kafka transaction decorator for both producer and consumer operations requires handling transactions in such a way that ensures message delivery guarantees (exactly-once semantics). This involves creating a decorator that manages transactional producers and consumers effectively.</p>\n",
    "<p>We'll use the <code>confluent_kafka</code> library, which supports Kafka's transactions. Below is an example showing how you can create these decorators.</p>\n",
    "\n",
    "<h3>Producer Transaction Decorator</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c84ecc-adcf-4f98-8a7c-3b8c58c304eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, KafkaException\n",
    "\n",
    "def kafka_producer_transaction_decorator(producer_conf):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            producer = Producer(producer_conf)\n",
    "            try:\n",
    "                producer.init_transactions()\n",
    "                producer.begin_transaction()\n",
    "                result = func(producer, *args, **kwargs)\n",
    "                producer.commit_transaction()\n",
    "            except KafkaException as e:\n",
    "                producer.abort_transaction()\n",
    "                raise e\n",
    "            finally:\n",
    "                producer.flush()\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b11107-dd7a-4fd5-a020-e7feb40b86a7",
   "metadata": {},
   "source": [
    "## Consumer Transaction Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543ebe-f144-4814-8761-5dc4ee2a305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError, KafkaException\n",
    "\n",
    "def kafka_consumer_transaction_decorator(consumer_conf, topics):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            consumer = Consumer(consumer_conf)\n",
    "            consumer.subscribe(topics)\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    msg = consumer.poll(timeout=1.0)\n",
    "                    if msg is None:\n",
    "                        continue\n",
    "                    if msg.error():\n",
    "                        if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                            # End of partition event\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise KafkaException(msg.error())\n",
    "                    \n",
    "                    producer = kwargs.get('producer')\n",
    "                    if not producer:\n",
    "                        raise ValueError(\"Producer is required to pass to the decorated function\")\n",
    "\n",
    "                    try:\n",
    "                        producer.init_transactions()\n",
    "                        producer.begin_transaction()\n",
    "                        func(msg.value(), producer, *args, **kwargs)\n",
    "                        producer.send_offsets_to_transaction(\n",
    "                            {msg.topic(): [(msg.partition(), msg.offset() + 1)]},\n",
    "                            consumer.consumer_group_metadata()\n",
    "                        )\n",
    "                        producer.commit_transaction()\n",
    "                    except KafkaException as e:\n",
    "                        producer.abort_transaction()\n",
    "                        raise e\n",
    "            finally:\n",
    "                consumer.close()\n",
    "        \n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87559d1c-7ec8-4211-a143-f13eed4859fa",
   "metadata": {},
   "source": [
    "### Example Usage\n",
    "Here's how you can use these decorators in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5c74f-e31b-44b6-ae5a-ffd689f17634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'transactional.id': 'my-transactional-producer'\n",
    "}\n",
    "\n",
    "# Example Kafka Consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-group',\n",
    "    'enable.auto.commit': False,\n",
    "    'isolation.level': 'read_committed'  # Important for transactions\n",
    "}\n",
    "\n",
    "@kafka_producer_transaction_decorator(producer_config)\n",
    "def produce_message(producer, some_data):\n",
    "    producer.produce('output-topic', key=None, value=some_data)\n",
    "\n",
    "@kafka_consumer_transaction_decorator(consumer_config, ['input-topic'])\n",
    "def consume_and_process_message(message, producer):\n",
    "    processed_data = f\"Processed {message}\"\n",
    "    produce_message(producer, processed_data)\n",
    "\n",
    "# Start consuming messages\n",
    "consume_and_process_message()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5cb29a-3131-4f63-809c-53ccab630545",
   "metadata": {},
   "source": [
    "***************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec04020-35dd-4958-9104-24e1ad6aca61",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Combined Transaction Decorators</h2>\n",
    "<p>Yes, we can create composite decorators that handle both database transactions and Kafka transactions. By nesting decorators, you can ensure that both types of transactions are managed properly within the scope of a single function.</p>\n",
    "<p>Below is an example implementation showing how you could combine database transaction management (using SQLAlchemy as an example) and Kafka transaction management in decorators:</p>\n",
    "\n",
    "<h3>Database Transaction Decorator</h3>\n",
    "<p>We'll use <code>SQLAlchemy</code> for this example. Ensure you have it installed (<code>pip install sqlalchemy</code>).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf667f45-2f21-4298-81ac-86b3525dd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///example.db')  # Example with SQLite\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def db_transaction_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        session = Session()\n",
    "        try:\n",
    "            result = func(session, *args, **kwargs)\n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            raise e\n",
    "        finally:\n",
    "            session.close()\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545bc965-2d57-4044-a880-c774a362c0ba",
   "metadata": {},
   "source": [
    "### Kafka Producer Transaction Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd4a2a-23ed-4af6-b569-a33e6a8e8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, KafkaException\n",
    "\n",
    "def kafka_producer_transaction_decorator(producer_conf):\n",
    "    def decorator(func):\n",
    "        def wrapper(session, *args, **kwargs):\n",
    "            producer = Producer(producer_conf)\n",
    "            try:\n",
    "                producer.init_transactions()\n",
    "                producer.begin_transaction()\n",
    "                result = func(session, producer, *args, **kwargs)\n",
    "                producer.commit_transaction()\n",
    "            except KafkaException as e:\n",
    "                producer.abort_transaction()\n",
    "                raise e\n",
    "            finally:\n",
    "                producer.flush()\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baec0b3-68cc-4b27-860f-1ab121923f3c",
   "metadata": {},
   "source": [
    "### Combined Usage\n",
    "Now we will combine these decorators and implement a function that uses both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3913c-d028-4292-9824-e345334f704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka Producer configuration\n",
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'transactional.id': 'my-transactional-producer'\n",
    "}\n",
    "\n",
    "@db_transaction_decorator\n",
    "@kafka_producer_transaction_decorator(producer_config)\n",
    "def complex_operation(session, producer, data):\n",
    "    # DB operations\n",
    "    session.add(data)  # Assuming `data` is an instance of an ORM-mapped class\n",
    "    \n",
    "    # Kafka operations\n",
    "    producer.produce('output-topic', key=None, value=str(data))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    from my_models import MyDataClass  # Import your SQLAlchemy models\n",
    "\n",
    "    new_data = MyDataClass(attribute='value')\n",
    "    complex_operation(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b99989-857e-4ec9-abf5-c43edee256ec",
   "metadata": {},
   "source": [
    "html\n",
    "<h2>Explanation</h2>\n",
    "\n",
    "<h3>Database Transaction Decorator (<code>db_transaction_decorator</code>):</h3>\n",
    "<ul>\n",
    "    <li>Manages a SQLAlchemy session.</li>\n",
    "    <li>Begins a transaction at the start and commits if the wrapped function succeeds.</li>\n",
    "    <li>Rolls back the transaction if any exception occurs and closes the session.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Kafka Producer Transaction Decorator (<code>kafka_producer_transaction_decorator</code>):</h3>\n",
    "<ul>\n",
    "    <li>Manages Kafka producer transactions.</li>\n",
    "    <li>Initializes and begins a transaction before calling the wrapped function.</li>\n",
    "    <li>Commits the Kafka transaction on success and aborts it on failure.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Combined Usage:</h3>\n",
    "<p>The <code>complex_operation</code> function is decorated with both decorators. It first interacts with the database using the SQLAlchemy session. Then it performs Kafka operations within the same transactional context. The nested decorators ensure that either all operations complete successfully or none do, maintaining consistency across both the database and Kafka.</p>\n",
    "\n",
    "<h3>Important Considerations:</h3>\n",
    "<ul>\n",
    "    <li>Ensure proper error handling to avoid partial updates in either system.</li>\n",
    "    <li>Make sure both decorators work cohesively to manage the transactions effectively.</li>\n",
    "    <li>This solution assumes that the potential side effects and performance overhead introduced by transactional management are acceptable for your specific scenario.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eb0a1-8b12-4f9e-8215-4c71c3432ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
