{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786f56b2-4c56-42c5-9ffa-c867af9e604d",
   "metadata": {},
   "source": [
    "# LLM Agent Framework\n",
    "\n",
    "\n",
    "Here are some of the top research papers on agent framework creation from arxiv.org:\n",
    "\n",
    "https://ar5iv.labs.arxiv.org/html/2407.10718\n",
    "https://ar5iv.labs.arxiv.org/html/2309.07870\n",
    "https://arxiv.org/pdf/2308.08155\n",
    "https://arxiv.org/html/2408.15247v1\n",
    "\n",
    "## IMPORTANT \n",
    "https://arxiv.org/html/2409.00608v1<br>\n",
    "https://arxiv.org/html/2406.11277v1<br>\n",
    "https://arxiv.org/abs/2304.03442<br>\n",
    "https://arxiv.org/abs/2401.07324<br>\n",
    "https://arxiv.org/html/2401.09680v2<br>\n",
    "https://arxiv.org/html/2406.02818v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f953d-cfdd-4d98-b206-f2bce3d0e357",
   "metadata": {},
   "source": [
    "### 1. Framework Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f43bf9-a495-47c3-b48e-da75f8fd26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_framework/\n",
    "├── agents/\n",
    "│   ├── __init__.py         # Package marker\n",
    "│   ├── agent.py            # Base agent class\n",
    "│   ├── llm_agent.py        # LLM agent implementation\n",
    "├── tasks/\n",
    "│   ├── __init__.py         # Package marker\n",
    "│   ├── task.py             # Base task class\n",
    "│   ├── llm_task.py         # LLM task implementation\n",
    "├── managers/\n",
    "│   ├── __init__.py         # Package marker\n",
    "│   ├── agent_manager.py     # Agent manager\n",
    "│   ├── task_manager.py      # Task manager\n",
    "├── strategies/\n",
    "│   ├── __init__.py         # Package marker\n",
    "│   ├── execution_strategy.py # Strategy for executing tasks\n",
    "├── main.py                 # Main entry point\n",
    "└── utils.py                # Utility functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc96126-4b06-4183-9ce6-fea80f89c1e9",
   "metadata": {},
   "source": [
    "### 2. Base Agent Class (agents/agent.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9466eab-6f90-4893-9be4-682b032be8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    def __init__(self, agent_id):\n",
    "        self.agent_id = agent_id\n",
    "\n",
    "    @abstractmethod\n",
    "    def execute(self, task):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87582c3e-8690-4ce8-929a-8cf9aa095f8e",
   "metadata": {},
   "source": [
    "### 3. LLM Agent Implementation (agents/llm_agent.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bcf19-ed11-461f-9f98-c6211c356828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .agent import BaseAgent\n",
    "\n",
    "class LLMAgent(BaseAgent):\n",
    "    def execute(self, task):\n",
    "        logging.info(f\"Agent {self.agent_id} executing task: {task.description}\")\n",
    "        # Simulate interaction with an LLM (e.g., API call)\n",
    "        response = f\"Result from Agent {self.agent_id} for task: {task.description}\"\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2bf68-2de6-41fd-b7a0-aadf885bb31e",
   "metadata": {},
   "source": [
    "### 4. Base Task Class (tasks/task.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc9547-5031-4179-9d49-428d38e5b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseTask(ABC):\n",
    "    @abstractmethod\n",
    "    def execute(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe34d48-3344-49e7-977c-ff8aa75a3ef9",
   "metadata": {},
   "source": [
    "### 5. LLM Task Implementation (tasks/llm_task.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566c999-037f-4639-8a12-2015467ff4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .task import BaseTask\n",
    "\n",
    "class LLTask(BaseTask):\n",
    "    def __init__(self, description):\n",
    "        self.description = description\n",
    "\n",
    "    def execute(self):\n",
    "        return f\"Task executed: {self.description}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72b248-894a-4e63-951d-fec090bcfe8f",
   "metadata": {},
   "source": [
    "### 6. Agent Manager (managers/agent_manager.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5f205-3772-4ced-aa8b-85ec1dc07f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from agents.llm_agent import LLMAgent\n",
    "from tasks.llm_task import LLTask\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class AgentManager:\n",
    "    def __init__(self, num_agents):\n",
    "        self.agents = [LLMAgent(i) for i in range(num_agents)]\n",
    "        self.results = []\n",
    "\n",
    "    def submit_task(self, task: LLTask):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            future_to_id = {executor.submit(agent.execute, task): agent.agent_id for agent in self.agents}\n",
    "            for future in as_completed(future_to_id):\n",
    "                agent_id = future_to_id[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    self.results.append(result)\n",
    "                    logging.info(f\"Agent {agent_id} completed task with result: {result}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in Agent {agent_id}: {e}\")\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b52bfd-2623-4796-bfbe-7d1a2fdb7cef",
   "metadata": {},
   "source": [
    "### 7. Task Manager (managers/task_manager.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e183559-134b-41fb-87b2-12cb3e190c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.llm_task import LLTask\n",
    "\n",
    "class TaskManager:\n",
    "    def create_tasks(self, descriptions):\n",
    "        return [LLTask(description) for description in descriptions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc44534-104b-4ac5-aadc-abc2f95322ac",
   "metadata": {},
   "source": [
    "### 8. Execution Strategy (strategies/execution_strategy.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2b806-1e48-470b-bbdc-490e5404f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from managers.agent_manager import AgentManager\n",
    "\n",
    "class ExecutionStrategy(ABC):\n",
    "    @abstractmethod\n",
    "    def execute(self, agent_manager: AgentManager, tasks):\n",
    "        pass\n",
    "\n",
    "class ConcurrentExecutionStrategy(ExecutionStrategy):\n",
    "    def execute(self, agent_manager: AgentManager, tasks):\n",
    "        for task in tasks:\n",
    "            agent_manager.submit_task(task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc55237-189c-45b6-9658-8b5295752274",
   "metadata": {},
   "source": [
    "### 9. Main Entry Point (main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b159bb-b77b-45fd-afbe-c97d3363670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from managers.agent_manager import AgentManager\n",
    "from managers.task_manager import TaskManager\n",
    "from strategies.execution_strategy import ConcurrentExecutionStrategy\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def main():\n",
    "    num_agents = 5  # Number of agents\n",
    "    descriptions = [f\"Task {i}\" for i in range(20)]  # Create 20 tasks\n",
    "\n",
    "    agent_manager = AgentManager(num_agents)\n",
    "    task_manager = TaskManager()\n",
    "    tasks = task_manager.create_tasks(descriptions)\n",
    "\n",
    "    strategy = ConcurrentExecutionStrategy()\n",
    "    strategy.execute(agent_manager, tasks)\n",
    "\n",
    "    results = agent_manager.get_results()\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6355c4-adbe-41cc-8006-1968aef93751",
   "metadata": {},
   "source": [
    "### 10. Utility Functions (utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a24998-b633-47b7-bf3e-8322e9c96707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging():\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Additional utility functions can be added here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df28d9c-7f11-4c1a-9f22-68a7c29fe8ea",
   "metadata": {},
   "source": [
    "__________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21437a06-c8e9-4e0b-a4a1-a3286c828334",
   "metadata": {},
   "source": [
    "## Updated Comprehensive LLM Agent Framework with Template Pattern and Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef173f-ce7f-4522-aeab-39a63095f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_framework/\n",
    "├── agents/\n",
    "│   ├── __init__.py         \n",
    "│   ├── agent.py            \n",
    "│   ├── llm_agent.py        \n",
    "├── tasks/\n",
    "│   ├── __init__.py         \n",
    "│   ├── task.py             \n",
    "│   ├── llm_task.py         \n",
    "│   ├── neural_network_task.py # Task that utilizes a neural network\n",
    "├── managers/\n",
    "│   ├── __init__.py         \n",
    "│   ├── agent_manager.py     \n",
    "│   ├── task_manager.py      \n",
    "├── strategies/\n",
    "│   ├── __init__.py         \n",
    "│   ├── execution_strategy.py \n",
    "├── templates/\n",
    "│   ├── __init__.py         \n",
    "│   ├── template.py          # Template Pattern implementation\n",
    "├── nn/\n",
    "│   ├── __init__.py         \n",
    "│   ├── neural_network.py     # Basic neural network implementation\n",
    "├── main.py                 \n",
    "└── utils.py                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74508ce-b7ee-4084-bdd6-367d86203948",
   "metadata": {},
   "source": [
    "### 2. Template Pattern Implementation (templates/template.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ea576-66ab-4902-8aa1-4771d2dc5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TaskTemplate(ABC):\n",
    "    def execute_task(self):\n",
    "        \"\"\"Template method defining the task execution steps.\"\"\"\n",
    "        self.prepare()\n",
    "        result = self.perform_task()\n",
    "        self.cleanup()\n",
    "        return result\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare(self):\n",
    "        \"\"\"Prepare for the task execution.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def perform_task(self):\n",
    "        \"\"\"Perform the main task logic.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup after task execution.\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e57559-9d42-4e9f-b969-dc5866a47587",
   "metadata": {},
   "source": [
    "### 3. Neural Network Implementation (nn/neural_network.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f64893-64b0-45b6-80cc-92be34375dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        self.hidden = self.sigmoid(np.dot(x, self.weights_input_hidden))\n",
    "        self.output = self.sigmoid(np.dot(self.hidden, self.weights_hidden_output))\n",
    "        return self.output\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        \"\"\"Sigmoid activation function.\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c04cba-461c-4153-88e0-bdd21bb1a601",
   "metadata": {},
   "source": [
    "### 4. Neural Network Task Implementation (tasks/neural_network_task.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e07ba3-8c8b-40a5-8089-4eb8530cac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .task import BaseTask\n",
    "from nn.neural_network import SimpleNeuralNetwork\n",
    "\n",
    "class NeuralNetworkTask(BaseTask):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.nn = SimpleNeuralNetwork(input_size=3, hidden_size=3, output_size=1)  # Example sizes\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"Execute the neural network forward pass on the data.\"\"\"\n",
    "        result = self.nn.forward(self.data)\n",
    "        return f\"Neural Network output: {result}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411431f-811e-4c9b-8613-ab62d264427a",
   "metadata": {},
   "source": [
    "### 5. LLM Task Implementation with Template Pattern (tasks/llm_task.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79bef4-b43f-4006-902d-57f5968e4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .task import BaseTask\n",
    "from templates.template import TaskTemplate\n",
    "\n",
    "class LLTask(TaskTemplate):\n",
    "    def __init__(self, description):\n",
    "        self.description = description\n",
    "\n",
    "    def prepare(self):\n",
    "        print(f\"Preparing task: {self.description}\")\n",
    "\n",
    "    def perform_task(self):\n",
    "        return f\"Task executed: {self.description}\"\n",
    "\n",
    "    def cleanup(self):\n",
    "        print(f\"Cleaning up task: {self.description}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f448ab-25aa-4d49-bb61-9602e344c896",
   "metadata": {},
   "source": [
    "### 6. Main Entry Point (main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4885e-49bc-4d01-b601-9ab41b49f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from managers.agent_manager import AgentManager\n",
    "from managers.task_manager import TaskManager\n",
    "from strategies.execution_strategy import ConcurrentExecutionStrategy\n",
    "from tasks.llm_task import LLTask\n",
    "from tasks.neural_network_task import NeuralNetworkTask\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def main():\n",
    "    num_agents = 5  # Number of agents\n",
    "    descriptions = [f\"Task {i}\" for i in range(10)]  # Create 10 LLM tasks\n",
    "    nn_data = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])  # Example input for neural network\n",
    "\n",
    "    agent_manager = AgentManager(num_agents)\n",
    "    task_manager = TaskManager()\n",
    "    \n",
    "    # Create LLM tasks\n",
    "    llm_tasks = task_manager.create_tasks(descriptions)\n",
    "    \n",
    "    # Create Neural Network task\n",
    "    nn_task = NeuralNetworkTask(nn_data)\n",
    "\n",
    "    # Combine tasks\n",
    "    tasks = llm_tasks + [nn_task]\n",
    "\n",
    "    strategy = ConcurrentExecutionStrategy()\n",
    "    strategy.execute(agent_manager, tasks)\n",
    "\n",
    "    results = agent_manager.get_results()\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46bd6e-c359-498b-9abe-a6da43dc8513",
   "metadata": {},
   "source": [
    "______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca3daef-9bfe-49cc-ae24-fc0b9ff63b97",
   "metadata": {},
   "source": [
    "## Core Program: LLM-Based Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df89840-0d33-439a-b7e0-e235427a3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "# Set up your API key for OpenAI (you can use any LLM API)\n",
    "openai.api_key = 'your-api-key-here'\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"\n",
    "    Client class for interacting with the LLM.\n",
    "    \"\"\"\n",
    "    async def query_llm(self, prompt: str) -> str:\n",
    "        response = await openai.ChatCompletion.acreate(\n",
    "            model=\"gpt-4\",  # Adjust the model as per availability\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Base class for an agent in the multi-agent system.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, llm_client: LLMClient):\n",
    "        self.name = name\n",
    "        self.llm_client = llm_client\n",
    "\n",
    "    async def perform_task(self, task: str) -> str:\n",
    "        \"\"\"\n",
    "        Each agent performs a specific task and may use the LLM to assist.\n",
    "        \"\"\"\n",
    "        prompt = f\"As an agent named {self.name}, how would I perform the task: '{task}'?\"\n",
    "        result = await self.llm_client.query_llm(prompt)\n",
    "        return f\"Agent {self.name} performed the task: {result}\"\n",
    "\n",
    "class ConversationAgent(Agent):\n",
    "    \"\"\"\n",
    "    Specialized agent for handling conversations.\n",
    "    \"\"\"\n",
    "    async def initiate_conversation(self, message: str) -> str:\n",
    "        prompt = f\"As a conversational agent, respond to the message: '{message}'\"\n",
    "        result = await self.llm_client.query_llm(prompt)\n",
    "        return f\"Agent {self.name} says: {result}\"\n",
    "\n",
    "class TaskManagerAgent(Agent):\n",
    "    \"\"\"\n",
    "    Specialized agent for managing tasks and delegating them to other agents.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, llm_client: LLMClient, agents: List[Agent]):\n",
    "        super().__init__(name, llm_client)\n",
    "        self.agents = agents\n",
    "\n",
    "    async def delegate_task(self, task: str) -> str:\n",
    "        \"\"\"\n",
    "        Task Manager delegates tasks to other agents.\n",
    "        \"\"\"\n",
    "        task_results = []\n",
    "        for agent in self.agents:\n",
    "            result = await agent.perform_task(task)\n",
    "            task_results.append(result)\n",
    "        return \"\\n\".join(task_results)\n",
    "\n",
    "async def main():\n",
    "    # Initialize LLM client\n",
    "    llm_client = LLMClient()\n",
    "\n",
    "    # Create agents\n",
    "    agent_1 = ConversationAgent(\"Agent_1\", llm_client)\n",
    "    agent_2 = Agent(\"Agent_2\", llm_client)\n",
    "\n",
    "    # TaskManager agent who will manage other agents\n",
    "    task_manager = TaskManagerAgent(\"TaskManager\", llm_client, [agent_1, agent_2])\n",
    "\n",
    "    # Perform tasks\n",
    "    result = await task_manager.delegate_task(\"Research topic on AI\")\n",
    "    print(result)\n",
    "\n",
    "    # Start conversation\n",
    "    conversation_result = await agent_1.initiate_conversation(\"What is the latest in AI?\")\n",
    "    print(conversation_result)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dece735-7666-4c86-bc0d-6ee6db6d5776",
   "metadata": {},
   "source": [
    "____________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681c3fc-42cd-4de5-a489-52a0e26cbc9a",
   "metadata": {},
   "source": [
    "# Architectural Overview\n",
    "\n",
    "## Layers\n",
    "\n",
    "1. **Presentation Layer**: Handles user interactions (CLI, Web API).\n",
    "2. **Service Layer**: Contains business logic and orchestrates agent interactions.\n",
    "3. **Agent Layer**: Implements various agent types with specific responsibilities.\n",
    "4. **Data Layer**: Manages data storage, retrieval, and interactions with external APIs (LLM).\n",
    "\n",
    "## Design Patterns\n",
    "\n",
    "- **Factory Pattern**: For creating agent instances based on type.\n",
    "- **Strategy Pattern**: For varying task execution strategies.\n",
    "- **Observer Pattern**: For agents to communicate changes to each other.\n",
    "- **Decorator Pattern**: To enhance agent functionalities without modifying existing code.\n",
    "- **Dependency Injection**: For managing dependencies, promoting decoupling and easier testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47585b0a-1bf1-4ee3-82b4-b5fc35629ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import asyncio\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# Set up your API key for OpenAI (you can use any LLM API)\n",
    "openai.api_key = 'your-api-key-here'\n",
    "\n",
    "# ------------------- Data Layer -------------------\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"Client class for interacting with the LLM.\"\"\"\n",
    "    \n",
    "    async def query_llm(self, prompt: str) -> str:\n",
    "        response = await openai.ChatCompletion.acreate(\n",
    "            model=\"gpt-4\",  # Adjust the model as per availability\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "\n",
    "# ------------------- Agent Layer -------------------\n",
    "\n",
    "class Agent(ABC):\n",
    "    \"\"\"Abstract base class for agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, llm_client: LLMClient):\n",
    "        self.name = name\n",
    "        self.llm_client = llm_client\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def perform_task(self, task: str) -> str:\n",
    "        pass\n",
    "\n",
    "class ConversationAgent(Agent):\n",
    "    \"\"\"Agent for handling conversations.\"\"\"\n",
    "    \n",
    "    async def perform_task(self, task: str) -> str:\n",
    "        prompt = f\"As a conversational agent named {self.name}, respond to: '{task}'\"\n",
    "        return await self.llm_client.query_llm(prompt)\n",
    "\n",
    "class ResearchAgent(Agent):\n",
    "    \"\"\"Agent for performing research tasks.\"\"\"\n",
    "    \n",
    "    async def perform_task(self, task: str) -> str:\n",
    "        prompt = f\"As a research agent named {self.name}, provide insights on: '{task}'\"\n",
    "        return await self.llm_client.query_llm(prompt)\n",
    "\n",
    "class AgentFactory:\n",
    "    \"\"\"Factory for creating agent instances.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_agent(agent_type: str, name: str, llm_client: LLMClient) -> Agent:\n",
    "        if agent_type == 'conversation':\n",
    "            return ConversationAgent(name, llm_client)\n",
    "        elif agent_type == 'research':\n",
    "            return ResearchAgent(name, llm_client)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown agent type: {agent_type}\")\n",
    "\n",
    "# ------------------- Service Layer -------------------\n",
    "\n",
    "class TaskManagerService:\n",
    "    \"\"\"Service class for managing tasks across agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: LLMClient):\n",
    "        self.llm_client = llm_client\n",
    "        self.agents: List[Agent] = []\n",
    "\n",
    "    def register_agent(self, agent: Agent):\n",
    "        self.agents.append(agent)\n",
    "\n",
    "    async def delegate_task(self, task: str) -> Dict[str, Any]:\n",
    "        results = {}\n",
    "        for agent in self.agents:\n",
    "            result = await agent.perform_task(task)\n",
    "            results[agent.name] = result\n",
    "        return results\n",
    "\n",
    "# ------------------- Presentation Layer -------------------\n",
    "\n",
    "class CommandLineInterface:\n",
    "    \"\"\"CLI for user interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, task_manager_service: TaskManagerService):\n",
    "        self.task_manager_service = task_manager_service\n",
    "\n",
    "    async def run(self):\n",
    "        print(\"Welcome to the Agent System!\")\n",
    "        while True:\n",
    "            task = input(\"Enter a task (or type 'exit' to quit): \")\n",
    "            if task.lower() == 'exit':\n",
    "                break\n",
    "            results = await self.task_manager_service.delegate_task(task)\n",
    "            for agent_name, result in results.items():\n",
    "                print(f\"{agent_name} says: {result}\")\n",
    "\n",
    "# ------------------- Main Execution -------------------\n",
    "\n",
    "async def main():\n",
    "    llm_client = LLMClient()\n",
    "    \n",
    "    # Create the task manager service\n",
    "    task_manager_service = TaskManagerService(llm_client)\n",
    "    \n",
    "    # Register agents\n",
    "    agent1 = AgentFactory.create_agent('conversation', 'ChatBot1', llm_client)\n",
    "    agent2 = AgentFactory.create_agent('research', 'ResearchBot1', llm_client)\n",
    "\n",
    "    task_manager_service.register_agent(agent1)\n",
    "    task_manager_service.register_agent(agent2)\n",
    "    \n",
    "    # Start the command line interface\n",
    "    cli = CommandLineInterface(task_manager_service)\n",
    "    await cli.run()\n",
    "\n",
    "# Entry point\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73468f75-8c5c-4e8e-a22d-4de414f049e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
